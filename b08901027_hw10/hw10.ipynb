{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "「hw10_adversarial_attack.ipynb」的副本",
      "provenance": [],
      "collapsed_sections": [
        "lhBJBAlKherZ",
        "uslb7GPchtMI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-n2e0BkhEKS"
      },
      "source": [
        "# **Homework 10 - Adversarial Attack**\n",
        "\n",
        "Slides: https://reurl.cc/v5kXkk\n",
        "\n",
        "Video(En): https://youtu.be/313TZsUDQ48\n",
        "\n",
        "Video(Zh): https://youtu.be/xWHpPEvkDiE\n",
        "\n",
        "TA: ntu-ml-2021spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpx02-fVo7_t",
        "outputId": "7fe999b0-c3f5-46f3-8e55-1fe7a0ed2e99"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May 27 23:31:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjc_QCXko-Ri",
        "outputId": "5766ebd0-f9be-42f3-c2af-7d2df116709e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dUXNJmmpBMu"
      },
      "source": [
        "import os\n",
        "\n",
        "# your workspace in your drive\n",
        "workspace = 'ML_HW10'\n",
        "\n",
        "try:\n",
        "  os.chdir(os.path.join('drive/My Drive/', workspace))\n",
        "except:\n",
        "  os.mkdir(os.path.join('drive/My Drive/', workspace))\n",
        "  os.chdir(os.path.join('drive/My Drive/', workspace))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RX7iRXrhMA_"
      },
      "source": [
        "## Enviroment & Download\n",
        "\n",
        "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMlu7VmGeuzw",
        "outputId": "6e18e311-81b9-4f33-d74b-e13cbbb18848"
      },
      "source": [
        "# set up environment\n",
        "!pip install pytorchcv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorchcv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/74/e5dae0875679d296fa9a3833041699cee9222e2d3dd1f9ae1ded050b5672/pytorchcv-0.0.65-py2.py3-none-any.whl (527kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 532kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorchcv) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorchcv) (2.10)\n",
            "Installing collected packages: pytorchcv\n",
            "Successfully installed pytorchcv-0.0.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Lw7urignqP"
      },
      "source": [
        "## download\n",
        "!gdown --id 1fHi1ko7wr80wXkXpqpqpOxuYH1mClXoX -O data.zip\n",
        "\n",
        "# unzip\n",
        "!unzip ./data.zip\n",
        "!rm ./data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQQf0l1hbBs"
      },
      "source": [
        "## Global Settings\n",
        "\n",
        "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
        "\n",
        "* Explaination (optional)\n",
        "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
        "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
        "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
        "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACghc_tsg2vE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# the mean and std are the calculated statistics from cifar_10 dataset\n",
        "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
        "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
        "\n",
        "# convert mean and std to 3-dimensional tensors for future operations\n",
        "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
        "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
        "\n",
        "epsilon = 8/255/std\n",
        "# TODO: iterative fgsm attack\n",
        "# alpha (step size) can be decided by yourself\n",
        "alpha = 0.1/255/std\n",
        "\n",
        "root = './data' # directory for storing benign images\n",
        "# benign images: images which do not contain adversarial perturbations\n",
        "# adversarial images: images which include adversarial perturbations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhBJBAlKherZ"
      },
      "source": [
        "## Data\n",
        "\n",
        "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXpRAHz0hkDt",
        "outputId": "108662fd-1854-4639-b11b-c514070574d5"
      },
      "source": [
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
        "])\n",
        "\n",
        "class AdvDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.names = []\n",
        "        '''\n",
        "        data_dir\n",
        "        ├── class_dir\n",
        "        │   ├── class1.png\n",
        "        │   ├── ...\n",
        "        │   ├── class20.png\n",
        "        '''\n",
        "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
        "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
        "            self.images += images\n",
        "            self.labels += ([i] * len(images))\n",
        "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.transform(Image.open(self.images[idx]))\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "    def __getname__(self):\n",
        "        return self.names\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "adv_set = AdvDataset(root, transform=transform)\n",
        "adv_names = adv_set.__getname__()\n",
        "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f'number of images = {adv_set.__len__()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of images = 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_pMkmPytX3k"
      },
      "source": [
        "## Model / Loss Function\n",
        "\n",
        "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5hbkOuN5KwR",
        "outputId": "f0cbe42b-67b5-41a6-f573-2372512141ee"
      },
      "source": [
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "from pytorchcv.model_provider import _models as all_model\n",
        "model_list = []\n",
        "for i in all_model.keys():\n",
        "    if (i.find('_cifar10') != -1) and (i.find('_cifar100') == -1):\n",
        "        model_list.append(i)\n",
        "\n",
        "model_list.remove('resnext20_16x4d_cifar10')\n",
        "model_list.remove('resnext20_32x2d_cifar10')\n",
        "model_list.remove('resnext20_32x4d_cifar10')\n",
        "model_list.remove('seresnet1001_cifar10')\n",
        "model_list.remove('seresnet1202_cifar10')\n",
        "model_list.remove('sepreresnet1001_cifar10')\n",
        "model_list.remove('sepreresnet1202_cifar10')\n",
        "model_list.remove('msdnet22_cifar10')\n",
        "model_list.remove('resdropresnet20_cifar10')\n",
        "model_list.remove('shakedropresnet20_cifar10')\n",
        "model_list.remove('fractalnet_cifar10')\n",
        "model_list.remove('diaresnet1001_cifar10')\n",
        "model_list.remove('diaresnet1202_cifar10')\n",
        "model_list.remove('diapreresnet1001_cifar10')\n",
        "model_list.remove('diapreresnet1202_cifar10')\n",
        "\n",
        "print(model_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nin_cifar10', 'resnet20_cifar10', 'resnet56_cifar10', 'resnet110_cifar10', 'resnet164bn_cifar10', 'resnet272bn_cifar10', 'resnet542bn_cifar10', 'resnet1001_cifar10', 'resnet1202_cifar10', 'preresnet20_cifar10', 'preresnet56_cifar10', 'preresnet110_cifar10', 'preresnet164bn_cifar10', 'preresnet272bn_cifar10', 'preresnet542bn_cifar10', 'preresnet1001_cifar10', 'preresnet1202_cifar10', 'resnext29_32x4d_cifar10', 'resnext29_16x64d_cifar10', 'resnext272_1x64d_cifar10', 'resnext272_2x32d_cifar10', 'seresnet20_cifar10', 'seresnet56_cifar10', 'seresnet110_cifar10', 'seresnet164bn_cifar10', 'seresnet272bn_cifar10', 'seresnet542bn_cifar10', 'sepreresnet20_cifar10', 'sepreresnet56_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'sepreresnet272bn_cifar10', 'sepreresnet542bn_cifar10', 'pyramidnet110_a48_cifar10', 'pyramidnet110_a84_cifar10', 'pyramidnet110_a270_cifar10', 'pyramidnet164_a270_bn_cifar10', 'pyramidnet200_a240_bn_cifar10', 'pyramidnet236_a220_bn_cifar10', 'pyramidnet272_a200_bn_cifar10', 'densenet40_k12_cifar10', 'densenet40_k12_bc_cifar10', 'densenet40_k24_bc_cifar10', 'densenet40_k36_bc_cifar10', 'densenet100_k12_cifar10', 'densenet100_k24_cifar10', 'densenet100_k12_bc_cifar10', 'densenet190_k40_bc_cifar10', 'densenet250_k24_bc_cifar10', 'xdensenet40_2_k24_bc_cifar10', 'xdensenet40_2_k36_bc_cifar10', 'wrn16_10_cifar10', 'wrn28_10_cifar10', 'wrn40_8_cifar10', 'wrn20_10_1bit_cifar10', 'wrn20_10_32bit_cifar10', 'ror3_56_cifar10', 'ror3_110_cifar10', 'ror3_164_cifar10', 'rir_cifar10', 'shakeshakeresnet20_2x16d_cifar10', 'shakeshakeresnet26_2x32d_cifar10', 'diaresnet20_cifar10', 'diaresnet56_cifar10', 'diaresnet110_cifar10', 'diaresnet164bn_cifar10', 'diapreresnet20_cifar10', 'diapreresnet56_cifar10', 'diapreresnet110_cifar10', 'diapreresnet164bn_cifar10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YJxK7YehqQy"
      },
      "source": [
        "## Utils -- Attack Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_1wKfKyhrQW"
      },
      "source": [
        "# perform fgsm attack\n",
        "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
        "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
        "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
        "    loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n",
        "    return x_adv\n",
        "\n",
        "# TODO: perform iterative fgsm attack################################################################################################################################\n",
        "# set alpha as the step size in Global Settings section\n",
        "# alpha and num_iter can be decided by yourself\n",
        "def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=400):\n",
        "    # initialize x_adv as original benign image x\n",
        "    x_adv = x.detach().clone()\n",
        "    # write a loop of num_iter to represent the iterative times\n",
        "    for i in range(num_iter):\n",
        "        # call fgsm with (epsilon = alpha) to obtain new x_adv\n",
        "        x_adv = fgsm(model, x_adv, y, loss_fn, alpha).detach().clone()\n",
        "        # clip new x_adv back to [x-epsilon, x+epsilon]\n",
        "        x_adv = torch.min(torch.max(x_adv, x - epsilon), x + epsilon)\n",
        "\n",
        "    return x_adv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYCEQwmcrmH6"
      },
      "source": [
        "## Utils -- Attack\n",
        "\n",
        "* Recall\n",
        "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "\n",
        "* Inverse function\n",
        "    * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
        "    * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
        "\n",
        "* Special Noted\n",
        "    * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
        "    * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5X_9x-7ro_w"
      },
      "source": [
        "# perform adversarial attack and generate adversarial examples\n",
        "def gen_adv_examples(model, loader, attack, loss_fn):\n",
        "    model.eval()\n",
        "    adv_names = []\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
        "        yp = model(x_adv)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "        # store adversarial examples\n",
        "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
        "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
        "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
        "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
        "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
        "\n",
        "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
        "\n",
        "# create directory which stores adversarial examples\n",
        "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
        "    if os.path.exists(adv_dir) is not True:\n",
        "        _ = shutil.copytree(data_dir, adv_dir)\n",
        "    for example, name in zip(adv_examples, adv_names):\n",
        "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
        "        im.save(os.path.join(adv_dir, name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnszlTsYrTQZ"
      },
      "source": [
        "## Utils -- Benign Images Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c_zZLzkrceE"
      },
      "source": [
        "# to evaluate the performance of model on benign images\n",
        "def epoch_benign(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        yp = model(x)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbEPaoOcgxTt"
      },
      "source": [
        "## Benign Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLxAOqghAo9",
        "outputId": "d1f68a2d-1398-43b7-f81f-80c1250b0c35"
      },
      "source": [
        "class Ensemble_Model(nn.Module):\n",
        "\n",
        "    def __init__(self, model_1, model_2, model_3, model_4, model_5, model_6):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.model_1 = model_1\n",
        "        self.model_2 = model_2\n",
        "        self.model_3 = model_3\n",
        "        self.model_4 = model_4\n",
        "        self.model_5 = model_5\n",
        "        self.model_6 = model_6\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = (self.model_1(x) + self.model_2(x) + self.model_3(x) + self.model_4(x) + self.model_5(x) + self.model_6(x)) / 6\n",
        "        return output\n",
        "\n",
        "model_1 = ptcv_get_model('resnet110_cifar10', pretrained=True).to(device)\n",
        "model_2 = ptcv_get_model('resnext272_2x32d_cifar10', pretrained=True).to(device)\n",
        "model_3 = ptcv_get_model('sepreresnet272bn_cifar10', pretrained=True).to(device)\n",
        "model_4 = ptcv_get_model('seresnet164bn_cifar10', pretrained=True).to(device)\n",
        "model_5 = ptcv_get_model('densenet250_k24_bc_cifar10', pretrained=True).to(device)\n",
        "model_6 = ptcv_get_model('pyramidnet272_a200_bn_cifar10', pretrained=True).to(device)\n",
        "model = Ensemble_Model(model_1, model_2, model_3, model_4, model_5, model_6).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.torch/models/resnet110_cifar10-0369-4d6ca1fc.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.163/resnet110_cifar10-0369-4d6ca1fc.pth.zip...\n",
            "Downloading /root/.torch/models/resnext272_2x32d_cifar10-0274-d2ace03c.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.375/resnext272_2x32d_cifar10-0274-d2ace03c.pth.zip...\n",
            "Downloading /root/.torch/models/sepreresnet272bn_cifar10-0339-606d0964.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.379/sepreresnet272bn_cifar10-0339-606d0964.pth.zip...\n",
            "Downloading /root/.torch/models/seresnet164bn_cifar10-0339-1085dab6.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.362/seresnet164bn_cifar10-0339-1085dab6.pth.zip...\n",
            "Downloading /root/.torch/models/densenet250_k24_bc_cifar10-0267-f8f9d305.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.290/densenet250_k24_bc_cifar10-0267-f8f9d305.pth.zip...\n",
            "Downloading /root/.torch/models/pyramidnet272_a200_bn_cifar10-0239-586b1ecd.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.284/pyramidnet272_a200_bn_cifar10-0239-586b1ecd.pth.zip...\n",
            "benign_acc = 0.97500, benign_loss = 0.10624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uslb7GPchtMI"
      },
      "source": [
        "## FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQwPTVUIhuTS"
      },
      "source": [
        "#adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n",
        "#print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n",
        "\n",
        "#create_dir(root, 'fgsm', adv_examples, adv_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXw6p0A6shZm"
      },
      "source": [
        "## I-FGSM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUEsT06Iskt2",
        "outputId": "a1587baf-90e9-47b5-baee-9b366789c0b0"
      },
      "source": [
        "# TODO: iterative fgsm attack\n",
        "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model, adv_loader, ifgsm, loss_fn)\n",
        "print(f'ifgsm_acc = {ifgsm_acc:.5f}, ifgsm_loss = {ifgsm_loss:.5f}')\n",
        "\n",
        "create_dir(root, 'ifgsm', adv_examples, adv_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picture 1 done.\n",
            "picture 2 done.\n",
            "picture 3 done.\n",
            "picture 4 done.\n",
            "picture 5 done.\n",
            "picture 6 done.\n",
            "picture 7 done.\n",
            "picture 8 done.\n",
            "picture 9 done.\n",
            "picture 10 done.\n",
            "picture 11 done.\n",
            "picture 12 done.\n",
            "picture 13 done.\n",
            "picture 14 done.\n",
            "picture 15 done.\n",
            "picture 16 done.\n",
            "picture 17 done.\n",
            "picture 18 done.\n",
            "picture 19 done.\n",
            "picture 20 done.\n",
            "picture 21 done.\n",
            "picture 22 done.\n",
            "picture 23 done.\n",
            "picture 24 done.\n",
            "picture 25 done.\n",
            "ifgsm_acc = 0.00000, ifgsm_loss = 23.49133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-nYkkYexEE"
      },
      "source": [
        "## Compress the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ItRo_S0M264N",
        "outputId": "31254976-7b00-4a90-c014-988ab3ffc078"
      },
      "source": [
        "#%cd fgsm\n",
        "#!tar zcvf ../fgsm.tgz *\n",
        "#%cd ..\n",
        "\n",
        "%cd ifgsm\n",
        "!tar zcvf ../ifgsm.tgz *\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML_HW10/ifgsm\n",
            "airplane/\n",
            "airplane/airplane1.png\n",
            "airplane/airplane12.png\n",
            "airplane/airplane13.png\n",
            "airplane/airplane11.png\n",
            "airplane/airplane10.png\n",
            "airplane/airplane16.png\n",
            "airplane/airplane17.png\n",
            "airplane/airplane15.png\n",
            "airplane/airplane14.png\n",
            "airplane/airplane19.png\n",
            "airplane/airplane18.png\n",
            "airplane/airplane20.png\n",
            "airplane/airplane2.png\n",
            "airplane/airplane3.png\n",
            "airplane/airplane4.png\n",
            "airplane/airplane5.png\n",
            "airplane/airplane6.png\n",
            "airplane/airplane8.png\n",
            "airplane/airplane7.png\n",
            "airplane/airplane9.png\n",
            "automobile/\n",
            "automobile/automobile1.png\n",
            "automobile/automobile12.png\n",
            "automobile/automobile11.png\n",
            "automobile/automobile10.png\n",
            "automobile/automobile13.png\n",
            "automobile/automobile14.png\n",
            "automobile/automobile16.png\n",
            "automobile/automobile15.png\n",
            "automobile/automobile17.png\n",
            "automobile/automobile19.png\n",
            "automobile/automobile18.png\n",
            "automobile/automobile2.png\n",
            "automobile/automobile20.png\n",
            "automobile/automobile3.png\n",
            "automobile/automobile4.png\n",
            "automobile/automobile5.png\n",
            "automobile/automobile6.png\n",
            "automobile/automobile7.png\n",
            "automobile/automobile8.png\n",
            "automobile/automobile9.png\n",
            "bird/\n",
            "bird/bird1.png\n",
            "bird/bird10.png\n",
            "bird/bird11.png\n",
            "bird/bird12.png\n",
            "bird/bird13.png\n",
            "bird/bird14.png\n",
            "bird/bird15.png\n",
            "bird/bird17.png\n",
            "bird/bird16.png\n",
            "bird/bird18.png\n",
            "bird/bird19.png\n",
            "bird/bird2.png\n",
            "bird/bird20.png\n",
            "bird/bird3.png\n",
            "bird/bird5.png\n",
            "bird/bird4.png\n",
            "bird/bird6.png\n",
            "bird/bird7.png\n",
            "bird/bird8.png\n",
            "bird/bird9.png\n",
            "cat/\n",
            "cat/cat1.png\n",
            "cat/cat10.png\n",
            "cat/cat11.png\n",
            "cat/cat12.png\n",
            "cat/cat13.png\n",
            "cat/cat14.png\n",
            "cat/cat15.png\n",
            "cat/cat17.png\n",
            "cat/cat16.png\n",
            "cat/cat19.png\n",
            "cat/cat18.png\n",
            "cat/cat2.png\n",
            "cat/cat20.png\n",
            "cat/cat3.png\n",
            "cat/cat4.png\n",
            "cat/cat6.png\n",
            "cat/cat5.png\n",
            "cat/cat8.png\n",
            "cat/cat7.png\n",
            "cat/cat9.png\n",
            "deer/\n",
            "deer/deer1.png\n",
            "deer/deer10.png\n",
            "deer/deer11.png\n",
            "deer/deer12.png\n",
            "deer/deer13.png\n",
            "deer/deer15.png\n",
            "deer/deer14.png\n",
            "deer/deer17.png\n",
            "deer/deer16.png\n",
            "deer/deer18.png\n",
            "deer/deer19.png\n",
            "deer/deer2.png\n",
            "deer/deer20.png\n",
            "deer/deer4.png\n",
            "deer/deer3.png\n",
            "deer/deer5.png\n",
            "deer/deer6.png\n",
            "deer/deer8.png\n",
            "deer/deer7.png\n",
            "deer/deer9.png\n",
            "dog/\n",
            "dog/dog10.png\n",
            "dog/dog15.png\n",
            "dog/dog12.png\n",
            "dog/dog1.png\n",
            "dog/dog13.png\n",
            "dog/dog11.png\n",
            "dog/dog14.png\n",
            "dog/dog16.png\n",
            "dog/dog17.png\n",
            "dog/dog18.png\n",
            "dog/dog19.png\n",
            "dog/dog6.png\n",
            "dog/dog3.png\n",
            "dog/dog2.png\n",
            "dog/dog4.png\n",
            "dog/dog5.png\n",
            "dog/dog20.png\n",
            "dog/dog8.png\n",
            "dog/dog7.png\n",
            "dog/dog9.png\n",
            "frog/\n",
            "frog/frog10.png\n",
            "frog/frog1.png\n",
            "frog/frog11.png\n",
            "frog/frog12.png\n",
            "frog/frog13.png\n",
            "frog/frog14.png\n",
            "frog/frog15.png\n",
            "frog/frog16.png\n",
            "frog/frog17.png\n",
            "frog/frog18.png\n",
            "frog/frog19.png\n",
            "frog/frog20.png\n",
            "frog/frog2.png\n",
            "frog/frog3.png\n",
            "frog/frog4.png\n",
            "frog/frog5.png\n",
            "frog/frog6.png\n",
            "frog/frog7.png\n",
            "frog/frog8.png\n",
            "frog/frog9.png\n",
            "horse/\n",
            "horse/horse1.png\n",
            "horse/horse10.png\n",
            "horse/horse11.png\n",
            "horse/horse12.png\n",
            "horse/horse13.png\n",
            "horse/horse14.png\n",
            "horse/horse15.png\n",
            "horse/horse16.png\n",
            "horse/horse17.png\n",
            "horse/horse18.png\n",
            "horse/horse19.png\n",
            "horse/horse2.png\n",
            "horse/horse20.png\n",
            "horse/horse3.png\n",
            "horse/horse4.png\n",
            "horse/horse5.png\n",
            "horse/horse6.png\n",
            "horse/horse7.png\n",
            "horse/horse8.png\n",
            "horse/horse9.png\n",
            "ship/\n",
            "ship/ship1.png\n",
            "ship/ship10.png\n",
            "ship/ship11.png\n",
            "ship/ship12.png\n",
            "ship/ship14.png\n",
            "ship/ship15.png\n",
            "ship/ship13.png\n",
            "ship/ship16.png\n",
            "ship/ship18.png\n",
            "ship/ship19.png\n",
            "ship/ship17.png\n",
            "ship/ship2.png\n",
            "ship/ship20.png\n",
            "ship/ship3.png\n",
            "ship/ship4.png\n",
            "ship/ship6.png\n",
            "ship/ship5.png\n",
            "ship/ship7.png\n",
            "ship/ship8.png\n",
            "ship/ship9.png\n",
            "truck/\n",
            "truck/truck1.png\n",
            "truck/truck10.png\n",
            "truck/truck11.png\n",
            "truck/truck13.png\n",
            "truck/truck12.png\n",
            "truck/truck14.png\n",
            "truck/truck15.png\n",
            "truck/truck16.png\n",
            "truck/truck17.png\n",
            "truck/truck18.png\n",
            "truck/truck19.png\n",
            "truck/truck2.png\n",
            "truck/truck20.png\n",
            "truck/truck3.png\n",
            "truck/truck5.png\n",
            "truck/truck4.png\n",
            "truck/truck6.png\n",
            "truck/truck7.png\n",
            "truck/truck8.png\n",
            "truck/truck9.png\n",
            "/content/drive/My Drive/ML_HW10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FM_S886kFd8"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FCuE2njkH1O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "c3a45307-8425-43c4-8847-65dccc3b5035"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10, 20))\n",
        "cnt = 0\n",
        "for i, cls_name in enumerate(classes):\n",
        "    path = f'{cls_name}/{cls_name}1.png'\n",
        "    # benign image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./data/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "    # adversarial image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./fgsm/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5d5b8cd7b95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/{path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}